---
# Source: sumologic/templates/logs/fluentd/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: RELEASE-NAME-sumologic-fluentd-logs
  labels:
    app: RELEASE-NAME-sumologic-fluentd-logs
    chart: "sumologic-%CURRENT_CHART_VERSION%"
    release: "RELEASE-NAME"
    heritage: "Helm"
data:
  fluent.conf: |-
    @include common.conf
    @include logs.conf
  buffer.output.conf: |
    compress "gzip"
    flush_interval "5s"
    flush_thread_count "8"
    chunk_limit_size "1m"
    total_limit_size "128m"
    queued_chunks_limit_size "128"
    overflow_action drop_oldest_chunk
    retry_max_interval "10m"
    retry_forever "true"
  common.conf: |-
    # Prevent fluentd from handling records containing its own logs and health checks.
    <match fluentd.pod.healthcheck>
      @type relabel
      @label @FLUENT_LOG
    </match>
    <label @FLUENT_LOG>
      <match **>
        @type null
      </match>
    </label>
    # expose the Fluentd metrics to Prometheus
    <source>
      @type prometheus
      metrics_path /metrics
      port 24231
    </source>
    <source>
      @type prometheus_output_monitor
    </source>
    <source>
      @type http
      port 9880
      bind 0.0.0.0
    </source>
    <system>
      log_level info
    </system>
  logs.conf: |
    <source>
      @type forward
      port 24321
      bind 0.0.0.0
      
    </source>
    @include logs.source.containers.conf
    @include logs.source.systemd.conf
    @include logs.source.default.conf
  logs.enhance.k8s.metadata.filter.conf: |
    cache_size  "10000"
    cache_ttl  "7200"
    cache_refresh "3600"
    cache_refresh_variation "900"
    in_namespace_path '$.kubernetes.namespace_name'
    in_pod_path '$.kubernetes.pod_name'
    core_api_versions v1
    api_groups apps/v1
    data_type logs
    add_owners true
    add_service true
    cache_refresh_apiserver_request_delay "0"
    cache_refresh_exclude_pod_regex ""
  logs.kubernetes.metadata.filter.conf: |
    annotation_match ["sumologic\.com.*"]
    de_dot false
    watch "true"
    ca_file ""
    verify_ssl "true"
    client_cert ""
    client_key ""
    bearer_token_file ""
    cache_size "10000"
    cache_ttl "7200"
    tag_to_kubernetes_name_regexp ".+?\\.containers\\.(?<pod_name>[^_]+)_(?<namespace>[^_]+)_(?<container_name>.+)-(?<docker_id>[a-z0-9]{64})\\.log$"
  logs.kubernetes.sumologic.filter.conf: |
    source_name "my_containers_sourceName"
    source_host "my_containers_sourceHost"
    log_format "fields"
    source_category "my_containers_sourceCategory"
    source_category_prefix "my_containers_sourceCategoryPrefix"
    source_category_replace_dash "my_containers_sourceCategoryReplaceDash"
    exclude_pod_regex "my_containers_excludePodRegex"
    exclude_container_regex "my_containers_excludeContainerRegex"
    exclude_host_regex "my_containers_excludeHostRegex"
    per_container_annotations_enabled false
    per_container_annotation_prefixes []
  logs.output.conf: |
    data_type logs
    log_key log
    endpoint "#{ENV['SUMO_ENDPOINT_DEFAULT_LOGS_SOURCE']}"
    verify_ssl "true"
    log_format "fields"
    add_timestamp "true"
    timestamp_key "timestamp"
    proxy_uri ""
    compress "true"
    compress_encoding "gzip"
  logs.source.containers.conf: |


    <filter containers.**>
      @type record_transformer
      enable_ruby
      renew_record true
      <record>
        # Converts {"log" => "{\"log\": \"foo \", \"stream\": \"stdout\", \"time\": \"1\"}\n\t{\"log\": \"bar\", \"stream\": \"stderr\", \"time\": \"2\"}\n\t"} to "foo bar"
        log    ${record["log"].split(/[\n\t]+/).map! {|item| JSON.parse(item)["log"]}.any? ? record["log"].split(/[\n\t]+/).map! {|item| JSON.parse(item)["log"]}.join("") : record["log"] rescue record["log"]}
        # Converts {"log" => "{\"log\": \"foo \", \"stream\": \"stdout\", \"time\": \"1\"}\n\t{\"log\": \"bar\", \"stream\": \"stderr\", \"time\": \"2\"}\n\t"} to "stderr"
        stream ${[record["log"].split(/[\n\t]+/)[0]].map! {|item| JSON.parse(item)["stream"]}.any? ? [record["log"].split(/[\n\t]+/)[0]].map! {|item| JSON.parse(item)["stream"]}.join("") : record["stream"] rescue record["stream"]}
        # Converts {"log" => "{\"log\": \"foo \", \"stream\": \"stdout\", \"time\": \"1\"}\n\t{\"log\": \"bar\", \"stream\": \"stderr\", \"time\": \"2\"}\n\t"} to "1"
        time   ${[record["log"].split(/[\n\t]+/)[0]].map! {|item| JSON.parse(item)["time"]}.any? ? [record["log"].split(/[\n\t]+/)[0]].map! {|item| JSON.parse(item)["time"]}.join("") : record["time"] rescue record["time"]}
      </record>
    </filter>
    # match all  container logs and label them @NORMAL
    <match containers.**>
      @type relabel
      @label @NORMAL
    </match>
    <label @NORMAL>

      # only match fluentd logs based on fluentd container log file name.
      # by default, this is <filter **collection-sumologic-fluentd**>
      <filter **RELEASE-NAME-sumologic-fluentd**>
        # only ingest:
        #   - stacktraces (containing /usr/local)
        #   - fluentd logs of levels: {error, fatal}: `\[error\]|\[fatal\]`
        #   - warning messages if buffer is full `drop_oldest_chunk|retry succeeded`
        @type grep
        <regexp>
          key log
          pattern /\/usr\/local|\[error\]|\[fatal\]|drop_oldest_chunk|retry succeeded/
        </regexp>
      </filter>







      # third-party Kubernetes metadata  filter plugin
      <filter containers.**>
        @type kubernetes_metadata
        @log_level error
        @include logs.kubernetes.metadata.filter.conf
      </filter>
      # Sumo Logic Kubernetes metadata enrichment filter plugin
      <filter containers.**>
        @type enhance_k8s_metadata
        @log_level error
        @include logs.enhance.k8s.metadata.filter.conf
      </filter>
      
      # Kubernetes Sumo Logic filter plugin
      <filter containers.**>
        @type kubernetes_sumologic
        @include logs.kubernetes.sumologic.filter.conf
        exclude_namespace_regex "my_containers_excludeNamespaceRegex"
      </filter>
      <filter **>
        @type record_modifier
        <record>
          _sumo_metadata ${record["_sumo_metadata"][:fields] = record["_sumo_metadata"].fetch(:fields, "").split(",").append("cluster=kubernetes").join(","); record["_sumo_metadata"]}
        </record>
      </filter>
      
      
      <match containers.**>
        @type copy
        <store>
          @type sumologic
          @id sumologic.endpoint.logs
          sumo_client "k8s_%CURRENT_CHART_VERSION%"
          @log_level error
          @include logs.output.conf
          <buffer>
            @type file
            path /fluentd/buffer/logs.containers
            @include buffer.output.conf
          </buffer>
        </store>
      </match>
    </label>
  logs.source.default.conf: |

    <filter **>
      @type grep
      <exclude>
        key message
        pattern /disable filter chain optimization/
      </exclude>
    </filter>
      
    <filter **>
      @type kubernetes_sumologic
      source_name "my_defaultFluentd_sourceName"
      source_category "my_defaultFluentd_sourceCategory"
      source_category_prefix "my_defaultFluentd_sourceCategoryPrefix"
      source_category_replace_dash "my_defaultFluentd_sourceCategoryReplaceDash"
      exclude_facility_regex "my_defaultFluentd_excludeFacilityRegex"
      exclude_host_regex "my_defaultFluentd_excludeHostRegex"
      exclude_priority_regex "my_defaultFluentd_excludePriorityRegex"
      exclude_unit_regex "my_defaultFluentd_excludeUnitRegex"
    </filter>
    <filter **>
      @type record_modifier
      <record>
        _sumo_metadata ${record["_sumo_metadata"][:fields] = record["_sumo_metadata"].fetch(:fields, "").split(",").append("cluster=kubernetes").join(","); record["_sumo_metadata"]}
      </record>
    </filter>
      
    <match **>
      @type copy
      <store>
        @type sumologic
        @id sumologic.endpoint.logs.default
        sumo_client "k8s_%CURRENT_CHART_VERSION%"
        @include logs.output.conf
        <buffer>
          @type file
          path /fluentd/buffer/logs.default
          @include buffer.output.conf
        </buffer>
      </store>
    </match>
  logs.source.systemd.conf: |

    <match host.kubelet.**>
      @type relabel
      @label @KUBELET
    </match>
    <label @KUBELET>
      
      <filter host.kubelet.**>
        @type kubernetes_sumologic
        source_category "my_kubelet_sourceCategory"
        source_name "my_kubelet_sourceName"
        source_category_prefix "my_kubelet_sourceCategoryPrefix"
        source_category_replace_dash "my_kubelet_sourceCategoryReplaceDash"
        exclude_facility_regex "my_kubelet_excludeFacilityRegex"
        exclude_host_regex "my_kubelet_excludeHostRegex"
        exclude_priority_regex "my_kubelet_excludePriorityRegex"
        exclude_unit_regex "my_kubelet_excludeUnitRegex"
      </filter>
      <filter **>
        @type record_modifier
        <record>
          _sumo_metadata ${record["_sumo_metadata"][:fields] = record["_sumo_metadata"].fetch(:fields, "").split(",").append("cluster=kubernetes").join(","); record["_sumo_metadata"]}
        </record>
      </filter>
      
      
      <match **>
        @type copy
        <store>
          @type sumologic
          @id sumologic.endpoint.logs.kubelet
          sumo_client "k8s_%CURRENT_CHART_VERSION%"
          @include logs.output.conf
          <buffer>
            @type file
            path /fluentd/buffer/logs.kubelet
            @include buffer.output.conf
          </buffer>
        </store>
      </match>
    </label>

    <match host.**>
      @type relabel
      @label @SYSTEMD
    </match>
    <label @SYSTEMD>
      
      <filter host.**>
        @type kubernetes_sumologic
        source_name "my_systemd_sourceName"
        source_category "my_systemd_sourceCategory"
        source_category_prefix "my_systemd_sourceCategoryPrefix"
        source_category_replace_dash "my_systemd_sourceCategoryReplaceDash"
        exclude_facility_regex "my_systemd_excludeFacilityRegex"
        exclude_host_regex "my_systemd_excludeHostRegex"
        exclude_priority_regex "my_systemd_excludePriorityRegex"
        exclude_unit_regex "my_systemd_excludeUnitRegex"
      </filter>
      <filter host.**>
        @type record_modifier
        <record>
          _sumo_metadata ${record["_sumo_metadata"][:source] = tag_parts[1]; record["_sumo_metadata"]}
        </record>
      </filter>
      <filter **>
        @type record_modifier
        <record>
          _sumo_metadata ${record["_sumo_metadata"][:fields] = record["_sumo_metadata"].fetch(:fields, "").split(",").append("cluster=kubernetes").join(","); record["_sumo_metadata"]}
        </record>
      </filter>
      
      
      <match **>
        @type copy
        <store>
          @type sumologic
          @id sumologic.endpoint.logs.systemd
          sumo_client "k8s_%CURRENT_CHART_VERSION%"
          @include logs.output.conf
          <buffer>
            @type file
            path /fluentd/buffer/logs.systemd
            @include buffer.output.conf
          </buffer>
        </store>
      </match>
    </label>
