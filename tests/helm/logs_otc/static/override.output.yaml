---
# Source: sumologic/templates/logs/collector/otelcol/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: RELEASE-NAME-sumologic-otelcol-logs-collector
  labels:
    app: RELEASE-NAME-sumologic-otelcol-logs-collector
    chart: "sumologic-%CURRENT_CHART_VERSION%"
    release: "RELEASE-NAME"
    heritage: "Helm"
data:
  config.yaml: |
    exporters:
      otlphttp:
        endpoint: http://${LOGS_METADATA_SVC}.${NAMESPACE}.svc.cluster.local:4318
    extensions:
      file_storage:
        compaction:
          directory: /var/lib/storage/otc
          on_rebound: true
          on_start: true
        directory: /var/lib/storage/otc
        timeout: 10s
      health_check: {}
      pprof: {}
    processors:
      batch:
        send_batch_size: 1000
        timeout: 1s
      logstransform/systemd:
        operators:
        - from: body._SYSTEMD_UNIT
          to: attributes._SYSTEMD_UNIT
          type: copy
        - from: body.SYSLOG_FACILITY
          to: attributes.SYSLOG_FACILITY
          type: copy
        - from: body._HOSTNAME
          to: attributes._HOSTNAME
          type: copy
        - from: body.PRIORITY
          to: attributes.PRIORITY
          type: copy
        - field: attributes["fluent.tag"]
          type: add
          value: EXPR("host." + attributes["_SYSTEMD_UNIT"])
        - field: body.__CURSOR
          type: remove
        - field: body.__MONOTONIC_TIMESTAMP
          type: remove
    receivers:
      filelog/containers:
        fingerprint_size: 17408
        include:
        - /var/log/pods/*/*/*.log
        include_file_name: false
        include_file_path: true
        operators:
        - id: get-format
          routes:
          - expr: body matches "^\\{"
            output: parser-docker
          - expr: body matches "^[^ Z]+ "
            output: parser-crio
          - expr: body matches "^[^ Z]+Z"
            output: parser-containerd
          type: router
        - id: parser-crio
          output: merge-cri-lines
          parse_to: body
          regex: ^(?P<time>[^ Z]+) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*)( |)(?P<log>.*)$
          timestamp:
            layout: "2006-01-02T15:04:05.000000000-07:00"
            layout_type: gotime
            parse_from: body.time
          type: regex_parser
        - id: parser-containerd
          output: merge-cri-lines
          parse_to: body
          regex: ^(?P<time>[^ ^Z]+Z) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*)( |)(?P<log>.*)$
          timestamp:
            layout: '%Y-%m-%dT%H:%M:%S.%LZ'
            parse_from: body.time
          type: regex_parser
        - id: parser-docker
          output: merge-docker-lines
          parse_to: body
          timestamp:
            layout: '%Y-%m-%dT%H:%M:%S.%LZ'
            parse_from: body.time
          type: json_parser
        - combine_field: body.log
          combine_with: ""
          id: merge-docker-lines
          is_last_entry: body.log matches "\n$"
          output: merge-multiline-logs
          source_identifier: attributes["log.file.path"]
          type: recombine
        - combine_field: body.log
          combine_with: ""
          id: merge-cri-lines
          is_last_entry: body.logtag == "F"
          output: merge-multiline-logs
          overwrite_with: newest
          source_identifier: attributes["log.file.path"]
          type: recombine
        - combine_field: body.log
          combine_with: ""
          id: merge-multiline-logs
          is_first_entry: body.log matches "^\\[?\\d{4}-\\d{1,2}-\\d{1,2}.\\d{2}:\\d{2}:\\d{2}"
          output: extract-metadata-from-filepath
          source_identifier: attributes["log.file.path"]
          type: recombine
        - id: extract-metadata-from-filepath
          parse_from: attributes["log.file.path"]
          regex: ^.*\/(?P<namespace>[^_]+)_(?P<pod_name>[^_]+)_(?P<uid>[a-f0-9\-]+)\/(?P<container_name>[^\._]+)\/(?P<run_id>\d+)\.log$
          type: regex_parser
        - from: body.stream
          id: move-attributes
          to: attributes["stream"]
          type: move
        - from: attributes.container_name
          to: attributes["k8s.container.name"]
          type: move
        - from: attributes.namespace
          to: attributes["k8s.namespace.name"]
          type: move
        - from: attributes.pod_name
          to: attributes["k8s.pod.name"]
          type: move
        - from: attributes.run_id
          to: attributes["run_id"]
          type: move
        - from: attributes.uid
          to: attributes["k8s.pod.uid"]
          type: move
        - field: attributes["fluent.tag"]
          type: add
          value: EXPR("containers." + attributes["k8s.container.name"])
        - field: attributes["log.file.path"]
          type: remove
        - from: body.log
          to: body
          type: move
        start_at: beginning
      journald:
        directory: /var/log/journal
        units:
        - docker.service
    service:
      extensions:
      - health_check
      - file_storage
      - pprof
      pipelines:
        logs/containers:
          exporters:
          - otlphttp
          processors:
          - batch
          receivers:
          - filelog/containers
        logs/systemd:
          exporters:
          - otlphttp
          processors:
          - logstransform/systemd
          - batch
          receivers:
          - journald
      telemetry:
        logs:
          level: info
