---
# Source: sumologic/templates/metrics/otelcol/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: RELEASE-NAME-sumologic-otelcol-metrics
  namespace: sumologic
  labels:
    app: RELEASE-NAME-sumologic-otelcol-metrics
    chart: "sumologic-%CURRENT_CHART_VERSION%"
    release: "RELEASE-NAME"
    heritage: "Helm"
data:
  config.yaml: |
    exporters:
      sumologic/default:
        client: k8s_%CURRENT_CHART_VERSION%
        decompose_otlp_histograms: true
        endpoint: ${SUMO_ENDPOINT_DEFAULT_OTLP_METRICS_SOURCE}
        max_request_body_size: 16777216
        metric_format: otlp
        sending_queue:
          enabled: true
          num_consumers: 10
          queue_size: 10000
          storage: file_storage
        timeout: 30s
    extensions:
      file_storage:
        compaction:
          directory: /tmp
          on_rebound: true
        directory: /var/lib/storage/otc
        timeout: 10s
      health_check:
        endpoint: ${env:MY_POD_IP}:13133
      pprof: {}
    processors:
      batch:
        send_batch_max_size: 2048
        send_batch_size: 1024
        timeout: 1s
      filter/drop_unnecessary_metrics:
        error_mode: ignore
        metrics:
          metric:
          - resource.attributes["job"] != "pod-annotations" and IsMatch(name, "scrape_.*")
          - (not IsMatch(name, "^$")) and (type == METRIC_DATA_TYPE_HISTOGRAM or type
            == METRIC_DATA_TYPE_EXPONENTIAL_HISTOGRAM or type == METRIC_DATA_TYPE_SUMMARY
            or IsMatch(name, ".*_bucket"))
      groupbyattrs:
        keys:
        - container
        - namespace
        - pod
        - service
      groupbyattrs/group_by_name:
        keys:
        - __name__
        - job
      k8sattributes:
        auth_type: serviceAccount
        extract:
          labels:
          - from: pod
            key_regex: (.*)
            tag_name: pod_labels_$$1
          metadata:
          - k8s.pod.name
          - k8s.deployment.name
          - k8s.daemonset.name
          - k8s.replicaset.name
          - k8s.statefulset.name
          - k8s.namespace.name
          - k8s.node.name
        passthrough: false
        pod_association:
        - sources:
          - from: resource_attribute
            name: k8s.pod.name
          - from: resource_attribute
            name: k8s.namespace.name
      memory_limiter:
        check_interval: 5s
        limit_percentage: 90
        spike_limit_percentage: 20
      metricstransform:
        transforms:
        - action: update
          include: ^prometheus_remote_write_(.*)$$
          match_type: regexp
          new_name: $$1
      resource:
        attributes:
        - action: upsert
          from_attribute: namespace
          key: k8s.namespace.name
        - action: delete
          key: namespace
        - action: upsert
          from_attribute: pod
          key: k8s.pod.name
        - action: delete
          key: pod
        - action: upsert
          from_attribute: container
          key: k8s.container.name
        - action: delete
          key: container
        - action: upsert
          from_attribute: node
          key: k8s.node.name
        - action: delete
          key: node
        - action: upsert
          from_attribute: service
          key: prometheus_service
        - action: delete
          key: service
        - action: upsert
          from_attribute: service.name
          key: job
        - action: delete
          key: service.name
        - action: upsert
          key: _origin
          value: kubernetes
        - action: upsert
          key: cluster
          value: kubernetes
      resource/delete_source_metadata:
        attributes:
        - action: delete
          key: _sourceCategory
        - action: delete
          key: _sourceHost
        - action: delete
          key: _sourceName
      resource/remove_k8s_pod_pod_name:
        attributes:
        - action: delete
          key: k8s.pod.pod_name
      source:
        collector: kubernetes
        exclude:
          k8s.namespace.name: ""
      sumologic:
        add_cloud_namespace: false
      transform/remove_name:
        error_mode: ignore
        metric_statements:
        - context: resource
          statements:
          - delete_key(attributes, "__name__")
      transform/set_name:
        error_mode: ignore
        metric_statements:
        - context: datapoint
          statements:
          - set(attributes["__name__"], metric.name) where IsMatch(metric.name, "^cloudprovider_.*")
    receivers:
      otlp:
        protocols:
          http:
            endpoint: ${env:MY_POD_IP}:4318
      telegraf:
        agent_config: |
          [agent]
            interval = "30s"
            flush_interval = "30s"
            omit_hostname = true
          [[inputs.http_listener_v2]]
            # wait longer than prometheus
            read_timeout = "30s"
            write_timeout = "30s"
            service_address = ":9888"
            data_format = "prometheusremotewrite"
            paths = [
              "/prometheus.metrics"
            ]
    service:
      extensions:
      - health_check
      - file_storage
      - pprof
      pipelines:
        metrics:
          exporters:
          - sumologic/default
          processors:
          - memory_limiter
          - metricstransform
          - groupbyattrs
          - resource
          - k8sattributes
          - source
          - sumologic
          - resource/remove_k8s_pod_pod_name
          - resource/delete_source_metadata
          - transform/set_name
          - groupbyattrs/group_by_name
          - transform/remove_name
          - filter/drop_unnecessary_metrics
          - batch
          receivers:
          - telegraf
          - otlp
      telemetry:
        logs:
          level: info
        metrics:
          level: normal
          readers:
          - pull:
              exporter:
                prometheus:
                  host: ${env:MY_POD_IP}
                  port: 8888
