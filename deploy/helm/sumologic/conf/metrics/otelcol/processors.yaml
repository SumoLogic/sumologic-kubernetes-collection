## Configuration for Batch Processor
## The batch processor accepts spans and places them into batches grouped by node and resource
batch:
  ## Maximum number of spans sent at once
  send_batch_max_size: 2_048
  ## Number of spans after which a batch will be sent regardless of time
  send_batch_size: 1_024
  ## Time duration after which a batch will be sent regardless of size
  timeout: 1s

filter/drop_unnecessary_metrics:
  error_mode: ignore
  metrics:
    metric:
      # we let the metrics from annotations ("kubernetes-pods") through as they are
      - resource.attributes["job"] != "pod-annotations" and IsMatch(name, "scrape_.*")
{{- if .Values.sumologic.metrics.dropHistogramBuckets }}
      # drop histograms we've extracted sums and counts from, but don't want the full thing
      - IsMatch(name, "^(apiserver_request_duration_seconds|coredns_dns_request_duration_seconds|kubelet_runtime_operations_duration_seconds)$")
{{- end }}

# Prometheus receiver puts all labels in record-level attributes, and we need them in resource
groupbyattrs:
  keys:
    - container
    - namespace
    - pod
    - service

groupbyattrs/group_by_name:
  keys:
    - __name__
    - job

## The Kubernetes sprocessor automatically tags logs, metrics and traces with Kubernetes metadata like pod name, namespace name etc.
k8s_tagger:
  extract:
    delimiter: "_"
    labels:
      - key: "*"
        tag_name: "pod_labels_%s"
    metadata:
      ## extract the following well-known metadata fields
      - daemonSetName
      - deploymentName
      - nodeName
      - replicaSetName
      - serviceName
      - statefulSetName
  owner_lookup_enabled: true  # To enable fetching additional metadata using `owner` relationship
  ## Has to be false to enrich metadata
  passthrough: false
  pod_association:
    - from: build_hostname  # Pods are identified by Pod name and namespace

## Configuration for Memory Limiter Processor
## The memory_limiter processor is used to prevent out of memory situations on the collector.
memory_limiter:
  ## check_interval is the time between measurements of memory usage for the
  ## purposes of avoiding going over the limits. Defaults to zero, so no
  ## checks will be performed. Values below 1 second are not recommended since
  ## it can result in unnecessary CPU consumption.
  check_interval: 5s
  ## Maximum amount of memory, in %, targeted to be allocated by the process heap.
  limit_percentage: 75
  ## Spike limit (calculated from available memory). Must be less than limit_percentage.
  spike_limit_percentage: 20

## Configuration for Metrics Transform Processor
metricstransform:
  transforms:
    ## rename all prometheus_remote_write_$name metrics to $name
    action: update
    include: ^prometheus_remote_write_(.*)$$
    match_type: regexp
    new_name: $$1

## Configuration for Resource Processor
resource:
  attributes:
    - action: upsert
      from_attribute: namespace
      key: k8s.namespace.name
    - action: delete
      key: namespace  # remove namespace to avoid duplication when attribute translation is enabled
    - action: upsert
      from_attribute: pod
      key: k8s.pod.name
    - action: delete
      key: pod  # remove pod to avoid duplication when attribute translation is enabled
    - action: upsert
      from_attribute: container
      key: k8s.container.name  # add container in OpenTelemetry convention to unify configuration for Source processor
    - action: delete
      key: container  # remove container to avoid duplication when attribute translation is enabled
    - action: upsert
      from_attribute: service
      key: prometheus_service
    - action: delete
      key: service
    - action: upsert
      from_attribute: service.name
      key: job
    - action: delete  # we don't want service.name to be set, as the schema processor translates it to "service"
      key: service.name
    - action: upsert
      key: _origin  # add "_origin" metadata to metrics to keep the same format as for metrics from Fluentd
      value: kubernetes
    - action: upsert
      key: cluster
      value: {{ .Values.sumologic.clusterName | quote }}

## NOTE: Drop these for now and and when proper configuration options
## are exposed and source processor is configured then send them
## as headers.
resource/delete_source_metadata:
  attributes:
    - action: delete
      key: _sourceCategory
    - action: delete
      key: _sourceHost
    - action: delete
      key: _sourceName
resource/remove_k8s_pod_pod_name:
  attributes:
    - action: delete
      key: k8s.pod.pod_name

{{- if eq .Values.sumologic.metrics.sourceType "http" }}
## NOTE: below listed rules could be simplified if routingprocessor
## supports regex matching. At this point we could group route entries
## going to the same set of exporters.
routing:
  attribute_source: resource
  default_exporters:
    - sumologic/default
  drop_resource_routing_attribute: true
  from_attribute: http_listener_v2_path
  table:
    ## apiserver metrics
    - exporters:
        - sumologic/apiserver
      value: /prometheus.metrics.apiserver
    ## control-plane metrics
    - exporters:
        - sumologic/control_plane
      value: /prometheus.metrics.control-plane.coredns
    - exporters:
        - sumologic/control_plane
      value: /prometheus.metrics.control-plane.kube-etcd
    ## controller metrics
    - exporters:
        - sumologic/controller
      value: /prometheus.metrics.controller-manager
    ## kubelet metrics
    - exporters:
        - sumologic/kubelet
      value: /prometheus.metrics.kubelet
    ## node metrics
    - exporters:
        - sumologic/node
      value: /prometheus.metrics.node
    ## scheduler metrics
    - exporters:
        - sumologic/scheduler
      value: /prometheus.metrics.scheduler
    ## state metrics
    - exporters:
        - sumologic/state
      value: /prometheus.metrics.state
    ## custom metrics
    ## This entry is necessary due to a bug in routing processor that prevents the routing key from being deleted
    ## if the default exporter is chosen
    ## See: https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/24644
    - exporters:
        - sumologic/default
      value: /prometheus.metrics.applications.custom
{{- end }}

## Configuration for Source Processor
## Source processor adds Sumo Logic related metadata
source:
  collector: {{ .Values.sumologic.collectorName | default .Values.sumologic.clusterName | quote }}
  exclude:
    k8s.namespace.name: {{ include "logs.excludeNamespaces" . }}

## The Sumo Logic Schema processor modifies the metadata on logs, metrics and traces sent to Sumo Logic
## so that the Sumo Logic apps can make full use of the ingested data.
sumologic_schema:
  add_cloud_namespace: false

{{- if eq .Values.sumologic.metrics.sourceType "http" }}
transform/prepare_routing:
  error_mode: ignore
  metric_statements:
    - context: metric
      statements:
        - set(resource.attributes["http_listener_v2_path"], "/prometheus.metrics.apiserver") where resource.attributes["job"] == "apiserver"
        - set(resource.attributes["http_listener_v2_path"], "/prometheus.metrics.control-plane.coredns") where resource.attributes["job"] == "coredns"
        - set(resource.attributes["http_listener_v2_path"], "/prometheus.metrics.control-plane.kube-etcd") where resource.attributes["job"] == "kube-etcd"
        - set(resource.attributes["http_listener_v2_path"], "/prometheus.metrics.controller-manager") where resource.attributes["job"] == "kubelet" and IsMatch(name, "^cloudprovider_.*")
        - set(resource.attributes["http_listener_v2_path"], "/prometheus.metrics.kubelet") where resource.attributes["job"] == "kubelet" and not IsMatch(name, "^cloudprovider_.*")
        - set(resource.attributes["http_listener_v2_path"], "/prometheus.metrics.node") where resource.attributes["job"] == "node-exporter"
        - set(resource.attributes["http_listener_v2_path"], "/prometheus.metrics.scheduler") where resource.attributes["job"] == "kube-scheduler"
        - set(resource.attributes["http_listener_v2_path"], "/prometheus.metrics.state") where resource.attributes["job"] == "kube-state-metrics"
{{ else }}
transform/drop_routing_attribute:
  error_mode: ignore
  metric_statements:
    - context: resource
      statements:
        - delete_key(attributes, "http_listener_v2_path")
{{- end }}

transform/remove_name:
  error_mode: ignore
  metric_statements:
    - context: resource
      statements:
        - delete_key(attributes, "__name__")

transform/set_name:
  error_mode: ignore
  metric_statements:
    - context: datapoint
      statements:
        - set(attributes["__name__"], metric.name) where IsMatch(metric.name, "^cloudprovider_.*")

{{- if .Values.sumologic.metrics.otelcol.extraProcessors }}
{{- range $processor := .Values.sumologic.metrics.otelcol.extraProcessors }}
{{ toYaml $processor }}
{{- end }}
{{- end }}
