# This file is auto-generated.
---
# Source: sumologic/templates/chart-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: sumologic-configmap
data:
  release: collection-sumologic-fluentd
  fluentdNamespace: $NAMESPACE
---
# Source: sumologic/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: collection-sumologic
  labels:
    app: collection-sumologic
    
data:
  fluent.conf: |-
    @include common.conf
    @include metrics.conf
    @include logs.conf
  buffer.output.conf: |-
    compress gzip
    flush_interval "5s"
    flush_thread_count "8"
    chunk_limit_size "1m"
    total_limit_size "128m"
    queued_chunks_limit_size "128"
    overflow_action drop_oldest_chunk
    
  common.conf: |-
    # Prevent fluentd from handling records containing its own logs.
    <match fluentd.**>
      @type null
    </match>
    # expose the Fluentd metrics to Prometheus
    <source>
      @type prometheus
      metrics_path /metrics
      port 24231
    </source>
    <source>
      @type prometheus_output_monitor
    </source>
    <source>
      @type http
      port 9880
      bind 0.0.0.0
    </source>
    <system>
      log_level info
    </system>
  
  metrics.conf: |-
    <source>
      @type http
      port 9888
      <parse>
        @type protobuf
      </parse>
    </source>
    <match prometheus.metrics**>
      @type datapoint
      @label @DATAPOINT
    </match>
    <label @DATAPOINT>
      <filter prometheus.metrics**> # NOTE: Remove this filter if you are running Kubernetes 1.13 or below.
        @type grep
        <exclude>
          key @metric
          pattern /^apiserver_request_count|^apiserver_request_latencies_summary|^kubelet_runtime_operations_latency_microseconds|^kubelet_docker_operations_latency_microseconds|^kubelet_docker_operations_errors$/
        </exclude>
      </filter>
      <filter prometheus.metrics**>
        @type record_modifier
        <record>
          cluster kubernetes
        </record>
      </filter>
      <filter prometheus.metrics**>
        @type enhance_k8s_metadata
        cache_size  "10000"
        cache_ttl  "3600"
        cache_refresh "1800"
      </filter>
      
      <filter prometheus.metrics**>
        @type prometheus_format
        relabel container_name:container,pod_name:pod
      </filter>
      
      <match prometheus.metrics.apiserver**>
        @type sumologic
        @id sumologic.endpoint.metrics.apiserver
        endpoint "#{ENV['SUMO_ENDPOINT_METRICS_APISERVER']}"
        @include metrics.output.conf
        <buffer>
          @type memory
          @include buffer.output.conf
        </buffer>
  
      </match>
      <match prometheus.metrics.kubelet**>
        @type sumologic
        @id sumologic.endpoint.metrics.kubelet
        endpoint "#{ENV['SUMO_ENDPOINT_METRICS_KUBELET']}"
        @include metrics.output.conf
        <buffer>
          @type memory
          @include buffer.output.conf
        </buffer>
      </match>
      <match prometheus.metrics.container**>
        @type sumologic
        @id sumologic.endpoint.metrics.container
        endpoint "#{ENV['SUMO_ENDPOINT_METRICS_KUBELET']}"
        @include metrics.output.conf
        <buffer>
          @type memory
          @include buffer.output.conf
        </buffer>
      </match>
      <match prometheus.metrics.controller-manager**>
        @type sumologic
        @id sumologic.endpoint.metrics.kube.controller.manager
        endpoint "#{ENV['SUMO_ENDPOINT_METRICS_KUBE_CONTROLLER_MANAGER']}"
        @include metrics.output.conf
        <buffer>
          @type memory
          @include buffer.output.conf
        </buffer>
      </match>
      <match prometheus.metrics.scheduler**>
        @type sumologic
        @id sumologic.endpoint.metrics.kube.scheduler
        endpoint "#{ENV['SUMO_ENDPOINT_METRICS_KUBE_SCHEDULER']}"
        @include metrics.output.conf
        <buffer>
          @type memory
          @include buffer.output.conf
        </buffer>
      </match>
      <match prometheus.metrics.state**>
        @type sumologic
        @id sumologic.endpoint.metrics.kube.state
        endpoint "#{ENV['SUMO_ENDPOINT_METRICS_KUBE_STATE']}"
        @include metrics.output.conf
        <buffer>
          @type memory
          @include buffer.output.conf
        </buffer>
      </match>
      <match prometheus.metrics.node**>
        @type sumologic
        @id sumologic.endpoint.metrics.node.exporter
        endpoint "#{ENV['SUMO_ENDPOINT_METRICS_NODE_EXPORTER']}"
        @include metrics.output.conf
        <buffer>
          @type memory
          @include buffer.output.conf
        </buffer>
      </match>
      <match prometheus.metrics**>
        @type sumologic
        @id sumologic.endpoint.metrics
        endpoint "#{ENV['SUMO_ENDPOINT_METRICS']}"
        @include metrics.output.conf
        <buffer>
          @type memory
          @include buffer.output.conf
        </buffer>
      </match>
    </label>
  metrics.output.conf: |-
    data_type metrics
    metric_data_format prometheus
    disable_cookies true
  
  logs.conf: |-
    <source>
      @type forward
      port 24321
      bind 0.0.0.0
    </source>
    @include logs.source.containers.conf
    @include logs.source.systemd.conf
    
    @include logs.source.default.conf
  logs.enhance.k8s.metadata.filter.conf: |-
    cache_size  "10000"
    cache_ttl  "3600"
    cache_refresh "1800"
    in_namespace_path '$.kubernetes.namespace_name'
    in_pod_path '$.kubernetes.pod_name'
    data_type logs
  logs.kubernetes.metadata.filter.conf: |-
    annotation_match ["sumologic\.com.*"]
    de_dot false
    watch "true"
    ca_file ""
    verify_ssl "true"
    client_cert ""
    client_key ""
    bearer_token_file ""
    cache_size "10000"
    cache_ttl "3600"
    tag_to_kubernetes_name_regexp '.+?\.containers\.(?<pod_name>[^_]+)_(?<namespace>[^_]+)_(?<container_name>.+)-(?<docker_id>[a-z0-9]{64})\.log$'
  logs.kubernetes.sumologic.filter.conf: |-
    source_name "%{namespace}.%{pod}.%{container}"
    source_host ""
    log_format "fields"
    source_category "%{namespace}/%{pod_name}"
    source_category_prefix "kubernetes/"
    source_category_replace_dash "/"
    exclude_namespace_regex ""
    exclude_pod_regex ""
    exclude_container_regex ""
    exclude_host_regex ""
  logs.output.conf: |-
    data_type logs
    log_key log
    endpoint "#{ENV['SUMO_ENDPOINT_LOGS']}"
    verify_ssl "true"
    log_format "fields"
    add_timestamp "true"
    timestamp_key "timestamp"
    proxy_uri ""
    
  logs.source.containers.conf: |
    <filter containers.**>
      @type record_transformer
      enable_ruby
      renew_record true
      <record>
        log    ${record["log"].split(/[\n\t]+/).map! {|item| JSON.parse(item)["log"]}.any? ? record["log"].split(/[\n\t]+/).map! {|item| JSON.parse(item)["log"]}.join("") : record["log"] rescue record["log"]}
        stream ${[record["log"].split(/[\n\t]+/)[0]].map! {|item| JSON.parse(item)["stream"]}.any? ? [record["log"].split(/[\n\t]+/)[0]].map! {|item| JSON.parse(item)["stream"]}.join("") : record["stream"] rescue record["stream"]}
        time   ${[record["log"].split(/[\n\t]+/)[0]].map! {|item| JSON.parse(item)["time"]}.any? ? [record["log"].split(/[\n\t]+/)[0]].map! {|item| JSON.parse(item)["time"]}.join("") : record["time"] rescue record["time"]}
      </record>
    </filter>
    # match all  container logs and label them @NORMAL
    <match containers.**>
      @type relabel
      @label @NORMAL
    </match>
    <label @NORMAL>
      #  only match fluentd logs based on fluentd container name
      <filter **collection-sumologic**>
        # only ingest fluentd logs of levels: {error, fatal} and warning messages if buffer is full
        @type grep
        <regexp>
          key log
          pattern /\[error\]|\[fatal\]|drop_oldest_chunk/
        </regexp>
      </filter>
      # third-party kubernetes metadata  filter plugin
      <filter containers.**>
        @type kubernetes_metadata
        @include logs.kubernetes.metadata.filter.conf
      </filter>
      # sumologic kubernetes metadata enrichment filter plugin
      <filter containers.**>
        @type enhance_k8s_metadata
        @include logs.enhance.k8s.metadata.filter.conf
      </filter>
      
      # kubernetes sumologic filter plugin
      <filter containers.**>
        @type kubernetes_sumologic
        @include logs.kubernetes.sumologic.filter.conf
      </filter>
      <match containers.**>
        @type sumologic
        @id sumologic.endpoint.logs
        @include logs.output.conf
        <buffer>
          @type memory
          @include buffer.output.conf
        </buffer>
      </match>
    </label>
  logs.source.default.conf: |-
    <match **>
      @type sumologic
      @id sumologic.endpoint.logs.default
      @include logs.output.conf
      <buffer>
        @type memory
        @include buffer.output.conf
      </buffer>
    </match>
  logs.source.systemd.conf: |-
    <match host.kubelet.**>
      @type relabel
      @label @KUBELET
    </match>
    <label @KUBELET>
      <filter host.kubelet.**>
        @type kubernetes_sumologic
        source_category "kubelet"
        source_name "k8s_kubelet"
        source_category_prefix "kubernetes/"
        source_category_replace_dash "/"
        exclude_facility_regex ""
        exclude_host_regex ""
        exclude_priority_regex ""
        exclude_unit_regex ""
      </filter>
      <match **>
        @type sumologic
        @id sumologic.endpoint.logs.kubelet
        @include logs.output.conf
        <buffer>
          @type memory
          @include buffer.output.conf
        </buffer>
      </match>
    </label>
    <match host.**>
      @type relabel
      @label @SYSTEMD
    </match>
    <label @SYSTEMD>
      <filter host.**>
        @type kubernetes_sumologic
        source_category "system"
        source_category_prefix "kubernetes/"
        source_category_replace_dash "/"
        exclude_facility_regex ""
        exclude_host_regex ""
        exclude_priority_regex ""
        exclude_unit_regex ""
      </filter>
      <filter host.**>
        @type record_modifier
        <record>
          _sumo_metadata ${record["_sumo_metadata"][:source] = tag_parts[1]; record["_sumo_metadata"]}
        </record>
      </filter>
      <match **>
        @type sumologic
        @id sumologic.endpoint.logs.systemd
        @include logs.output.conf
        <buffer>
          @type memory
          @include buffer.output.conf
        </buffer>
      </match>
    </label>
  
---
# Source: sumologic/templates/events-configmap.yaml

apiVersion: v1
kind: ConfigMap
metadata:
  name: collection-sumologic-events
  labels:
    app: collection-sumologic-events
    
data:
  fluent.conf: |-
    @include events.conf
  events.conf: |-
    <source>
      @type events
      deploy_namespace $NAMESPACE
    </source>
    # Prevent fluentd from handling records containing its own logs.
    <match fluentd.**>
      @type null
    </match>
    # expose the Fluentd metrics to Prometheus
    <source>
      @type prometheus
      metrics_path /metrics
      port 24231
    </source>
    <source>
      @type prometheus_output_monitor
    </source>
    <source>
      @type http
      port 9880
      bind 0.0.0.0
    </source>
    <match kubernetes.**>
      @type sumologic
      @id sumologic.endpoint.events
      endpoint "#{ENV['SUMO_ENDPOINT_EVENTS']}"
      data_type logs
      disable_cookies true
      verify_ssl "true"
      proxy_uri ""
      <buffer>
        @type memory
        @include buffer.output.conf
      </buffer>
    </match>
    <system>
      log_level info
    </system>
  
  buffer.output.conf: |-
    compress gzip
    flush_interval "5s"
    flush_thread_count "8"
    chunk_limit_size "1m"
    total_limit_size "128m"
    queued_chunks_limit_size "128"
    overflow_action drop_oldest_chunk
    
  
---
# Source: sumologic/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: collection-sumologic
  labels:
    app: collection-sumologic
    
---
# Source: sumologic/templates/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: collection-sumologic
  labels:
    app: collection-sumologic
    
rules:
- apiGroups: ["", "apps", "extensions", "events.k8s.io"]
  resources:
  - configmaps
  - daemonsets
  - deployments
  - endpoints
  - events
  - namespaces
  - nodes
  - pods
  - replicasets
  - services
  - statefulsets
  verbs: ["get", "list", "watch"]
- apiGroups: [""]
  resources:
    - configmaps
  verbs: ["create", "patch"]
---
# Source: sumologic/templates/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: collection-sumologic
  labels:
    app: collection-sumologic
    
subjects:
- kind: ServiceAccount
  namespace: $NAMESPACE
  name: collection-sumologic
roleRef:
  kind: ClusterRole
  name: collection-sumologic
  apiGroup: rbac.authorization.k8s.io
---
# Source: sumologic/templates/events-service-headless.yaml

apiVersion: v1
kind: Service
metadata:
  name: collection-sumologic-events-headless
  labels:
    app: collection-sumologic-events
    
spec:
  selector:
    app: collection-sumologic-events
  clusterIP: None
  ports:
  - name: metrics
    port: 24231
    targetPort: 24231
    protocol: TCP
---
# Source: sumologic/templates/events-service.yaml

apiVersion: v1
kind: Service
metadata:
  name: collection-sumologic-events
  labels:
    app: collection-sumologic-events
    
spec:
  selector:
    app: collection-sumologic-events
  ports:
  - name: metrics
    port: 24231
    targetPort: 24231
    protocol: TCP
---
# Source: sumologic/templates/service-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: collection-sumologic-headless
  labels:
    app: collection-sumologic
    
spec:
  selector:
    app: collection-sumologic
  clusterIP: None
  ports:
  - name: prom-write
    port: 9888
    targetPort: 9888
    protocol: TCP
  - name: fluent-bit
    port: 24321
    targetPort: 24321
    protocol: TCP
  - name: metrics
    port: 24231
    targetPort: 24231
    protocol: TCP

---
# Source: sumologic/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: collection-sumologic
  labels:
    app: collection-sumologic
    
spec:
  selector:
    app: collection-sumologic
  ports:
  - name: prom-write
    port: 9888
    targetPort: 9888
    protocol: TCP
  - name: fluent-bit
    port: 24321
    targetPort: 24321
    protocol: TCP
  - name: metrics
    port: 24231
    targetPort: 24231
    protocol: TCP

---
# Source: sumologic/templates/events-statefulset.yaml

apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: collection-sumologic-events-fluentd
  labels:
    app: collection-sumologic-events
    
spec:
  selector:
    matchLabels:
      app: collection-sumologic-events
  serviceName: collection-sumologic-events-headless
  podManagementPolicy: "Parallel"
  template:
    metadata:
      labels:
        app: collection-sumologic-events
        
    spec:
      serviceAccountName: collection-sumologic
      volumes:
      - name: pos-files
        hostPath:
          path: /var/run/fluentd-pos
          type: ""
      - name: config-volume
        configMap:
          name: collection-sumologic-events
      securityContext:
        fsGroup: 999
      containers:
      - name: fluentd-events
        image: sumologic/kubernetes-fluentd:1.0.0-beta.0
        imagePullPolicy: IfNotPresent
        resources:
          limits:
            cpu: 100m
            memory: 256Mi
          requests:
            cpu: 100m
            memory: 256Mi
          
        volumeMounts:
        - name: config-volume
          mountPath: /fluentd/etc/
        - name: pos-files
          mountPath: /mnt/pos/
        livenessProbe:
          httpGet:
            path: /fluentd.pod.healthcheck?json=%7B%22log%22%3A+%22health+check%22%7D
            port: 9880
          initialDelaySeconds: 300
          periodSeconds: 30
          timeoutSeconds: 3
        readinessProbe:
          httpGet:
            path: /fluentd.pod.healthcheck?json=%7B%22log%22%3A+%22health+check%22%7D
            port: 9880
          initialDelaySeconds: 30
          periodSeconds: 5
        env:
        - name: SUMO_ENDPOINT_EVENTS
          valueFrom:
            secretKeyRef:
              name: sumologic
              key: endpoint-events
---
# Source: sumologic/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: collection-sumologic-fluentd
  labels:
    app: collection-sumologic
    
spec:
  selector:
    matchLabels:
      app: collection-sumologic
  serviceName: collection-sumologic-headless
  podManagementPolicy: "Parallel"
  replicas: 3
  template:
    metadata:
      labels:
        app: collection-sumologic
        
    spec:
      serviceAccountName: collection-sumologic
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - collection-sumologic
                - key: app
                  operator: In
                  values:
                  - prometheus-operator-prometheus
              topologyKey: "kubernetes.io/hostname"
      volumes:
      - name: pos-files
        hostPath:
          path: /var/run/fluentd-pos
          type: ""
      - name: config-volume
        configMap:
          name: collection-sumologic
      securityContext:
        fsGroup: 999
      containers:
      - name: fluentd
        image: sumologic/kubernetes-fluentd:1.0.0-beta.0
        imagePullPolicy: IfNotPresent
        resources:
          limits:
            cpu: 1
            memory: 1Gi
          requests:
            cpu: 0.5
            memory: 768Mi
          
        ports:
        - name: prom-write
          containerPort: 9888
          protocol: TCP
        - name: fluent-bit
          containerPort: 24321
          protocol: TCP
        livenessProbe:
          httpGet:
            path: /fluentd.pod.healthcheck?json=%7B%22log%22%3A+%22health+check%22%7D
            port: 9880
          initialDelaySeconds: 300
          periodSeconds: 30
          timeoutSeconds: 3
        readinessProbe:
          httpGet:
            path: /fluentd.pod.healthcheck?json=%7B%22log%22%3A+%22health+check%22%7D
            port: 9880
          initialDelaySeconds: 30
          periodSeconds: 5
        volumeMounts:
        - name: config-volume
          mountPath: /fluentd/etc/
        - name: pos-files
          mountPath: /mnt/pos/
        env:
        - name: SUMO_ENDPOINT_METRICS
          valueFrom:
            secretKeyRef:
              name: sumologic
              key: endpoint-metrics
        - name: SUMO_ENDPOINT_METRICS_APISERVER
          valueFrom:
            secretKeyRef:
              name: sumologic
              key: endpoint-metrics-apiserver
        - name: SUMO_ENDPOINT_METRICS_KUBELET
          valueFrom:
            secretKeyRef:
              name: sumologic
              key: endpoint-metrics-kubelet
        - name: SUMO_ENDPOINT_METRICS_KUBE_CONTROLLER_MANAGER
          valueFrom:
            secretKeyRef:
              name: sumologic
              key: endpoint-metrics-kube-controller-manager
        - name: SUMO_ENDPOINT_METRICS_KUBE_SCHEDULER
          valueFrom:
            secretKeyRef:
              name: sumologic
              key: endpoint-metrics-kube-scheduler
        - name: SUMO_ENDPOINT_METRICS_KUBE_STATE
          valueFrom:
            secretKeyRef:
              name: sumologic
              key: endpoint-metrics-kube-state
        - name: SUMO_ENDPOINT_METRICS_NODE_EXPORTER
          valueFrom:
            secretKeyRef:
              name: sumologic
              key: endpoint-metrics-node-exporter
        - name: SUMO_ENDPOINT_LOGS
          valueFrom:
            secretKeyRef:
              name: sumologic
              key: endpoint-logs
        - name: ADDITIONAL_PLUGINS
          value: ""
---
# Source: sumologic/templates/hpa.yaml

---
# Source: sumologic/templates/otelcol-configmap.yaml

---
# Source: sumologic/templates/otelcol-deployment.yaml


---
# Source: sumologic/templates/otelcol-service.yaml

